{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c0b920b-9364-4593-8bde-0b363e5fe320",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(style=\"darkgrid\")\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "import string\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a66dc2d-969e-4e1e-8e58-5e3b04c3e6d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Training Examples = 891\n",
      "Number of Test Examples = 418\n",
      "\n",
      "Training X Shape = (891, 12)\n",
      "Training y Shape = 891\n",
      "\n",
      "Test X Shape = (418, 11)\n",
      "Test y Shape = 418\n",
      "\n",
      "Index(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',\n",
      "       'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked'],\n",
      "      dtype='object')\n",
      "Index(['PassengerId', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch',\n",
      "       'Ticket', 'Fare', 'Cabin', 'Embarked'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "def concat_df(train_data, test_data):\n",
    "    # Returns a concatenated df of training and test set\n",
    "    return pd.concat([train_data, test_data], sort=True).reset_index(drop=True)\n",
    "def divide_df(all_data):\n",
    "    # Returns divided dfs of training and test set\n",
    "    return all_data.loc[:890], all_data.loc[891:].drop(['Survived'], axis=1)\n",
    "df_train = pd.read_csv(r\"C:\\Users\\Nusrat Fatima Khan\\OneDrive\\Desktop\\Titanic Feature Engineering\\train.csv\")\n",
    "df_test = pd.read_csv(r\"C:\\Users\\Nusrat Fatima Khan\\OneDrive\\Desktop\\Titanic Feature Engineering\\test.csv\")\n",
    "df_all = concat_df(df_train, df_test)\n",
    "\n",
    "df_train.name = 'Training Set'\n",
    "df_test.name = 'Test Set'\n",
    "df_all.name = 'All Set' \n",
    "\n",
    "dfs = [df_train, df_test]\n",
    "\n",
    "print('Number of Training Examples = {}'.format(df_train.shape[0]))\n",
    "print('Number of Test Examples = {}\\n'.format(df_test.shape[0]))\n",
    "print('Training X Shape = {}'.format(df_train.shape))\n",
    "print('Training y Shape = {}\\n'.format(df_train['Survived'].shape[0]))\n",
    "print('Test X Shape = {}'.format(df_test.shape))\n",
    "print('Test y Shape = {}\\n'.format(df_test.shape[0]))\n",
    "print(df_train.columns)\n",
    "print(df_test.columns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a1d39d3-329c-4c83-9e6b-1fccb06321a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#**Exploratory Data Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d863e2db-9e7e-4aab-8ec4-aa6b080f3b66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>625</th>\n",
       "      <td>626</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Sutton, Mr. Frederick</td>\n",
       "      <td>male</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>36963</td>\n",
       "      <td>32.3208</td>\n",
       "      <td>D50</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>300</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Baxter, Mrs. James (Helene DeLaudeniere Chaput)</td>\n",
       "      <td>female</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>PC 17558</td>\n",
       "      <td>247.5208</td>\n",
       "      <td>B58 B60</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>828</th>\n",
       "      <td>829</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>McCormack, Mr. Thomas Joseph</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>367228</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass  \\\n",
       "625          626         0       1   \n",
       "299          300         1       1   \n",
       "828          829         1       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "625                            Sutton, Mr. Frederick    male  61.0      0   \n",
       "299  Baxter, Mrs. James (Helene DeLaudeniere Chaput)  female  50.0      0   \n",
       "828                     McCormack, Mr. Thomas Joseph    male   NaN      0   \n",
       "\n",
       "     Parch    Ticket      Fare    Cabin Embarked  \n",
       "625      0     36963   32.3208      D50        S  \n",
       "299      1  PC 17558  247.5208  B58 B60        C  \n",
       "828      0    367228    7.7500      NaN        Q  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df_train.info())\n",
    "df_train.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38d57acc-fd56-4d28-8c6e-02db15487a0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 418 entries, 0 to 417\n",
      "Data columns (total 11 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  418 non-null    int64  \n",
      " 1   Pclass       418 non-null    int64  \n",
      " 2   Name         418 non-null    object \n",
      " 3   Sex          418 non-null    object \n",
      " 4   Age          332 non-null    float64\n",
      " 5   SibSp        418 non-null    int64  \n",
      " 6   Parch        418 non-null    int64  \n",
      " 7   Ticket       418 non-null    object \n",
      " 8   Fare         417 non-null    float64\n",
      " 9   Cabin        91 non-null     object \n",
      " 10  Embarked     418 non-null    object \n",
      "dtypes: float64(2), int64(4), object(5)\n",
      "memory usage: 36.1+ KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>1198</td>\n",
       "      <td>1</td>\n",
       "      <td>Allison, Mr. Hudson Joshua Creighton</td>\n",
       "      <td>male</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>999</td>\n",
       "      <td>3</td>\n",
       "      <td>Ryan, Mr. Edward</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>383162</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>Myles, Mr. Thomas Francis</td>\n",
       "      <td>male</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>240276</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Pclass                                  Name   Sex   Age  \\\n",
       "306         1198       1  Allison, Mr. Hudson Joshua Creighton  male  30.0   \n",
       "107          999       3                      Ryan, Mr. Edward  male   NaN   \n",
       "2            894       2             Myles, Mr. Thomas Francis  male  62.0   \n",
       "\n",
       "     SibSp  Parch  Ticket      Fare    Cabin Embarked  \n",
       "306      1      2  113781  151.5500  C22 C26        S  \n",
       "107      0      0  383162    7.7500      NaN        Q  \n",
       "2        0      0  240276    9.6875      NaN        Q  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df_test.info())\n",
    "df_test.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c4c60b2-f4a8-42ff-baa5-4ffe57b32edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#**MISSING VALUES**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f1beda1d-aab3-4222-a457-eb522f853b08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set\n",
      "PassengerId column missing values: 0\n",
      "Survived column missing values: 0\n",
      "Pclass column missing values: 0\n",
      "Name column missing values: 0\n",
      "Sex column missing values: 0\n",
      "Age column missing values: 177\n",
      "SibSp column missing values: 0\n",
      "Parch column missing values: 0\n",
      "Ticket column missing values: 0\n",
      "Fare column missing values: 0\n",
      "Cabin column missing values: 687\n",
      "Embarked column missing values: 2\n",
      "\n",
      "\n",
      "Test Set\n",
      "PassengerId column missing values: 0\n",
      "Pclass column missing values: 0\n",
      "Name column missing values: 0\n",
      "Sex column missing values: 0\n",
      "Age column missing values: 86\n",
      "SibSp column missing values: 0\n",
      "Parch column missing values: 0\n",
      "Ticket column missing values: 0\n",
      "Fare column missing values: 1\n",
      "Cabin column missing values: 327\n",
      "Embarked column missing values: 0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def display_missing(df):    \n",
    "    for col in df.columns.tolist():          \n",
    "        print('{} column missing values: {}'.format(col, df[col].isnull().sum()))\n",
    "    print('\\n')\n",
    "    \n",
    "for df in dfs:\n",
    "    print('{}'.format(df.name))\n",
    "    display_missing(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "48d9fe35-9bc0-41f8-8b49-e4a0d6d892a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#**AGE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ff30a6ce-8dd0-4828-8447-d5c35c0ea9fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Feature 1    Feature 2  Correlation Coefficient\n",
      "1        Age  PassengerId                      1.0\n",
      "5        Age         Fare                      1.0\n",
      "6        Age          Age                      1.0\n",
      "7        Age        SibSp                      1.0\n",
      "28       Age       Pclass                      NaN\n",
      "29       Age        Parch                      NaN\n",
      "30       Age        Cabin                      NaN\n"
     ]
    }
   ],
   "source": [
    "# Updated DataFrame based on your provided data\n",
    "data = {\n",
    "    'PassengerId': [1091, 1002, 905],\n",
    "    'Pclass': [3, 2, 2],\n",
    "    'Name': ['Rasmussen, Mrs. (Lena Jacobsen Solvang)', 'Stanton, Mr. Samuel Ward', 'Howard, Mr. Benjamin'],\n",
    "    'Sex': ['female', 'male', 'male'],\n",
    "    'Age': [np.nan, 41.0, 63.0],\n",
    "    'SibSp': [0, 0, 1],\n",
    "    'Parch': [0, 0, 0],\n",
    "    'Ticket': ['65305', '237734', '24065'],\n",
    "    'Fare': [8.1125, 15.0458, 26.0000],\n",
    "    'Cabin': [np.nan, np.nan, np.nan],\n",
    "    'Embarked': ['S', 'C', 'S']\n",
    "}\n",
    "\n",
    "df_all = pd.DataFrame(data)\n",
    "\n",
    "# Select only numeric columns\n",
    "df_numeric = df_all.select_dtypes(include=[np.number])\n",
    "\n",
    "# Handle missing values (optional): fill with a specific value, or drop rows/columns\n",
    "# For simplicity, we'll use forward fill to fill missing values\n",
    "df_numeric = df_numeric.fillna(method='ffill')  # You could also use other methods like mean imputation\n",
    "\n",
    "# Calculate correlations\n",
    "df_all_corr = df_numeric.corr().abs().unstack().sort_values(kind=\"quicksort\", ascending=False).reset_index()\n",
    "df_all_corr.rename(columns={\"level_0\": \"Feature 1\", \"level_1\": \"Feature 2\", 0: 'Correlation Coefficient'}, inplace=True)\n",
    "\n",
    "# Filter correlations involving 'Age'\n",
    "age_correlations = df_all_corr[df_all_corr['Feature 1'] == 'Age']\n",
    "\n",
    "print(age_correlations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8f688673-9037-420f-bd06-3658bd541bc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median age of Pclass 1 females: Not available\n",
      "Median age of Pclass 1 males: Not available\n",
      "Median age of Pclass 2 females: Not available\n",
      "Median age of Pclass 2 males: 52.0\n",
      "Median age of Pclass 3 females: nan\n",
      "Median age of Pclass 3 males: Not available\n",
      "Median age of all passengers: 52.0\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "incompatible index of inserted column with frame index",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:12304\u001b[0m, in \u001b[0;36m_reindex_for_setitem\u001b[1;34m(value, index)\u001b[0m\n\u001b[0;32m  12303\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m> 12304\u001b[0m     reindexed_value \u001b[38;5;241m=\u001b[39m value\u001b[38;5;241m.\u001b[39mreindex(index)\u001b[38;5;241m.\u001b[39m_values\n\u001b[0;32m  12305\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m  12306\u001b[0m     \u001b[38;5;66;03m# raised in MultiIndex.from_tuples, see test_insert_error_msmgs\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\series.py:4981\u001b[0m, in \u001b[0;36mSeries.reindex\u001b[1;34m(self, index, axis, method, copy, level, fill_value, limit, tolerance)\u001b[0m\n\u001b[0;32m   4964\u001b[0m \u001b[38;5;129m@doc\u001b[39m(\n\u001b[0;32m   4965\u001b[0m     NDFrame\u001b[38;5;241m.\u001b[39mreindex,  \u001b[38;5;66;03m# type: ignore[has-type]\u001b[39;00m\n\u001b[0;32m   4966\u001b[0m     klass\u001b[38;5;241m=\u001b[39m_shared_doc_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mklass\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4979\u001b[0m     tolerance\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   4980\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Series:\n\u001b[1;32m-> 4981\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mreindex(\n\u001b[0;32m   4982\u001b[0m         index\u001b[38;5;241m=\u001b[39mindex,\n\u001b[0;32m   4983\u001b[0m         method\u001b[38;5;241m=\u001b[39mmethod,\n\u001b[0;32m   4984\u001b[0m         copy\u001b[38;5;241m=\u001b[39mcopy,\n\u001b[0;32m   4985\u001b[0m         level\u001b[38;5;241m=\u001b[39mlevel,\n\u001b[0;32m   4986\u001b[0m         fill_value\u001b[38;5;241m=\u001b[39mfill_value,\n\u001b[0;32m   4987\u001b[0m         limit\u001b[38;5;241m=\u001b[39mlimit,\n\u001b[0;32m   4988\u001b[0m         tolerance\u001b[38;5;241m=\u001b[39mtolerance,\n\u001b[0;32m   4989\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:5521\u001b[0m, in \u001b[0;36mNDFrame.reindex\u001b[1;34m(self, labels, index, columns, axis, method, copy, level, fill_value, limit, tolerance)\u001b[0m\n\u001b[0;32m   5520\u001b[0m \u001b[38;5;66;03m# perform the reindex on the axes\u001b[39;00m\n\u001b[1;32m-> 5521\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_axes(\n\u001b[0;32m   5522\u001b[0m     axes, level, limit, tolerance, method, fill_value, copy\n\u001b[0;32m   5523\u001b[0m )\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreindex\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:5544\u001b[0m, in \u001b[0;36mNDFrame._reindex_axes\u001b[1;34m(self, axes, level, limit, tolerance, method, fill_value, copy)\u001b[0m\n\u001b[0;32m   5543\u001b[0m ax \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_axis(a)\n\u001b[1;32m-> 5544\u001b[0m new_index, indexer \u001b[38;5;241m=\u001b[39m ax\u001b[38;5;241m.\u001b[39mreindex(\n\u001b[0;32m   5545\u001b[0m     labels, level\u001b[38;5;241m=\u001b[39mlevel, limit\u001b[38;5;241m=\u001b[39mlimit, tolerance\u001b[38;5;241m=\u001b[39mtolerance, method\u001b[38;5;241m=\u001b[39mmethod\n\u001b[0;32m   5546\u001b[0m )\n\u001b[0;32m   5548\u001b[0m axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_axis_number(a)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:4438\u001b[0m, in \u001b[0;36mIndex.reindex\u001b[1;34m(self, target, method, level, limit, tolerance)\u001b[0m\n\u001b[0;32m   4436\u001b[0m             indexer, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_indexer_non_unique(target)\n\u001b[1;32m-> 4438\u001b[0m target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wrap_reindex_result(target, indexer, preserve_names)\n\u001b[0;32m   4439\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m target, indexer\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\multi.py:2602\u001b[0m, in \u001b[0;36mMultiIndex._wrap_reindex_result\u001b[1;34m(self, target, indexer, preserve_names)\u001b[0m\n\u001b[0;32m   2601\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 2602\u001b[0m     target \u001b[38;5;241m=\u001b[39m MultiIndex\u001b[38;5;241m.\u001b[39mfrom_tuples(target)\n\u001b[0;32m   2603\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   2604\u001b[0m     \u001b[38;5;66;03m# not all tuples, see test_constructor_dict_multiindex_reindex_flat\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\multi.py:220\u001b[0m, in \u001b[0;36mnames_compat.<locals>.new_meth\u001b[1;34m(self_or_cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m    218\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 220\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m meth(self_or_cls, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\multi.py:615\u001b[0m, in \u001b[0;36mMultiIndex.from_tuples\u001b[1;34m(cls, tuples, sortorder, names)\u001b[0m\n\u001b[0;32m    613\u001b[0m         tuples \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(tuples\u001b[38;5;241m.\u001b[39m_values)\n\u001b[1;32m--> 615\u001b[0m     arrays \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(lib\u001b[38;5;241m.\u001b[39mtuples_to_object_array(tuples)\u001b[38;5;241m.\u001b[39mT)\n\u001b[0;32m    616\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tuples, \u001b[38;5;28mlist\u001b[39m):\n",
      "File \u001b[1;32mlib.pyx:2983\u001b[0m, in \u001b[0;36mpandas._libs.lib.tuples_to_object_array\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Buffer dtype mismatch, expected 'Python object' but got 'long long'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_18292\\390941319.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mfill_age_with_group_median\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Sex'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Pclass'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Age'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmedian\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;31m# Apply the filling function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m \u001b[0mdf_all\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Age'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfill_age_with_group_median\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_all\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;31m# Verify results\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_all\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   4087\u001b[0m             \u001b[1;31m# Column to set is duplicated\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4088\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_setitem_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4089\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4090\u001b[0m             \u001b[1;31m# set column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4091\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   4296\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4297\u001b[0m         \u001b[0mSeries\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mTimeSeries\u001b[0m \u001b[0mwill\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mconformed\u001b[0m \u001b[0mto\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mDataFrames\u001b[0m \u001b[0mindex\u001b[0m \u001b[0mto\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4298\u001b[0m         \u001b[0mensure\u001b[0m \u001b[0mhomogeneity\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4299\u001b[0m         \"\"\"\n\u001b[1;32m-> 4300\u001b[1;33m         \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrefs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sanitize_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4301\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4302\u001b[0m         if (\n\u001b[0;32m   4303\u001b[0m             \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, value)\u001b[0m\n\u001b[0;32m   5032\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5033\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_dict_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5034\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5035\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSeries\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5036\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0m_reindex_for_setitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5037\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5038\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_list_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5039\u001b[0m             \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequire_length_match\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(value, index)\u001b[0m\n\u001b[0;32m  12307\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  12308\u001b[0m             \u001b[1;31m# duplicate axis\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  12309\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  12310\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m> 12311\u001b[1;33m         raise TypeError(\n\u001b[0m\u001b[0;32m  12312\u001b[0m             \u001b[1;34m\"incompatible index of inserted column with frame index\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  12313\u001b[0m         ) from err\n\u001b[0;32m  12314\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mreindexed_value\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: incompatible index of inserted column with frame index"
     ]
    }
   ],
   "source": [
    "data = {\n",
    "    'PassengerId': [1091, 1002, 905],\n",
    "    'Pclass': [3, 2, 2],\n",
    "    'Name': ['Rasmussen, Mrs. (Lena Jacobsen Solvang)', 'Stanton, Mr. Samuel Ward', 'Howard, Mr. Benjamin'],\n",
    "    'Sex': ['female', 'male', 'male'],\n",
    "    'Age': [np.nan, 41.0, 63.0],\n",
    "    'SibSp': [0, 0, 1],\n",
    "    'Parch': [0, 0, 0],\n",
    "    'Ticket': ['65305', '237734', '24065'],\n",
    "    'Fare': [8.1125, 15.0458, 26.0000],\n",
    "    'Cabin': [np.nan, np.nan, np.nan],\n",
    "    'Embarked': ['S', 'C', 'S']\n",
    "}\n",
    "\n",
    "df_all = pd.DataFrame(data)\n",
    "\n",
    "# Step 1: Calculate median age by 'Sex' and 'Pclass'\n",
    "age_by_pclass_sex = df_all.groupby(['Sex', 'Pclass'])['Age'].median()\n",
    "\n",
    "# Print median age for each combination of 'Sex' and 'Pclass'\n",
    "for pclass in range(1, 4):\n",
    "    for sex in ['female', 'male']:\n",
    "        # Check if the group exists in the median DataFrame\n",
    "        if (sex, pclass) in age_by_pclass_sex.index:\n",
    "            print(f'Median age of Pclass {pclass} {sex}s: {age_by_pclass_sex[sex][pclass]}')\n",
    "        else:\n",
    "            print(f'Median age of Pclass {pclass} {sex}s: Not available')\n",
    "\n",
    "# Print median age of all passengers\n",
    "print(f'Median age of all passengers: {df_all[\"Age\"].median()}')\n",
    "\n",
    "# Step 2: Fill missing values in 'Age' with median values from 'Sex' and 'Pclass' groups\n",
    "def fill_age_with_group_median(df):\n",
    "    return df.groupby(['Sex', 'Pclass'])['Age'].apply(lambda x: x.fillna(x.median()))\n",
    "\n",
    "# Apply the filling function\n",
    "df_all['Age'] = fill_age_with_group_median(df_all)\n",
    "\n",
    "# Verify results\n",
    "print(df_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e52d2f38-b13c-40e9-ab84-054437b9f3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_all.columns)\n",
    "\n",
    "df_all.columns = df_all.columns.str.strip()\n",
    "\n",
    "print(df_all.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e28bbf-99f0-4945-93bf-0d970c368130",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Example DataFrame (adjust according to your actual data)\n",
    "df_all = pd.DataFrame({\n",
    "    'Sex': ['female', 'male', 'female', 'male'],\n",
    "    'Pclass': [1, 2, 1, 3],\n",
    "    'Age': [22, 25, 30, 29]\n",
    "})\n",
    "\n",
    "# Check column names\n",
    "print(\"Columns in DataFrame:\", df_all.columns)\n",
    "\n",
    "# Strip whitespace from column names (if needed)\n",
    "df_all.columns = df_all.columns.str.strip()\n",
    "\n",
    "# Verify the DataFrame\n",
    "print(df_all.head())\n",
    "\n",
    "# Perform the groupby operation\n",
    "age_by_pclass_sex = df_all.groupby(['Sex', 'Pclass']).median()['Age']\n",
    "\n",
    "print(age_by_pclass_sex)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37cb57d3-539b-46ee-a643-10b46a953a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example DataFrame (adjust according to your actual data)\n",
    "df_all = pd.DataFrame({\n",
    "    'Sex': ['female', 'male', 'female', 'male'],\n",
    "    'Pclass': [1, 2, 1, 3],\n",
    "    'Age': [22, 25, 30, 29]\n",
    "})\n",
    "\n",
    "# Calculate median age by Sex and Pclass\n",
    "age_by_pclass_sex = df_all.groupby(['Sex', 'Pclass']).median()['Age']\n",
    "\n",
    "# Print median ages\n",
    "for pclass in range(1, 4):\n",
    "    for sex in ['female', 'male']:\n",
    "        if (sex, pclass) in age_by_pclass_sex.index:\n",
    "            median_age = age_by_pclass_sex.loc[sex, pclass]\n",
    "            print('Median age of Pclass {} {}s: {}'.format(pclass, sex, median_age))\n",
    "        else:\n",
    "            print('Median age of Pclass {} {}s: Not available'.format(pclass, sex))\n",
    "\n",
    "# Print the median age of all passengers\n",
    "print('Median age of all passengers: {}'.format(df_all['Age'].median()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db2b2d9e-8e02-466f-a57e-f73983bb1541",
   "metadata": {},
   "outputs": [],
   "source": [
    "#**EMBARKED**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9af0799-0a21-47a6-a185-9231ea76f9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example DataFrame creation (replace with your actual data loading method)\n",
    "df_all = pd.DataFrame({\n",
    "    'PassengerId': [1, 2, 3],\n",
    "    'Pclass': [1, 2, 3],\n",
    "    'Name': ['A', 'B', 'C'],\n",
    "    'Age': [22, 38, 26]\n",
    "    # 'Embarked' column is intentionally missing here for illustration\n",
    "})\n",
    "\n",
    "# Print columns to verify existence of 'Embarked'\n",
    "print(\"Columns in DataFrame:\", df_all.columns)\n",
    "\n",
    "# Strip any extra spaces from column names\n",
    "df_all.columns = df_all.columns.str.strip()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5312f02-f1a4-4e42-8962-dd9e04444e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for the presence of 'Embarked'\n",
    "if 'Embarked' in df_all.columns:\n",
    "    # Perform operations if 'Embarked' exists\n",
    "    print(df_all[df_all['Embarked'].isnull()])\n",
    "else:\n",
    "    print(\"'Embarked' column is not present in the DataFrame\")\n",
    "\n",
    "\n",
    "# Filling the missing values in Embarked with S\n",
    "df_all[df_all['Embarked'].isnull()]\n",
    "\n",
    "df_all['Embarked'] = 'S'\n",
    "\n",
    "print(df_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef6366d4-8194-4ee8-9d82-fbbac827203f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#**FARE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3308cd09-ff5b-4802-850f-f142f86d462e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = pd.DataFrame({\n",
    "    'PassengerId': [1, 2, 3],\n",
    "    'Pclass': [1, 2, 3],\n",
    "    'Name': ['A', 'B', 'C'],\n",
    "    'Age': [22, 38, 26]\n",
    "    # 'fare' column is intentionally missing here for illustration\n",
    "})\n",
    "\n",
    "# Print columns to verify existence of 'fare'\n",
    "print(\"Columns in DataFrame:\", df_all.columns)\n",
    "\n",
    "# Strip any extra spaces from column names\n",
    "df_all.columns = df_all.columns.str.strip()\n",
    "\n",
    "# Check for the presence of 'Embarked'\n",
    "if 'fare' in df_all.columns:\n",
    "    # Perform operations if 'Embarked' exists\n",
    "    print(df_all[df_all['fare'].isnull()])\n",
    "else:\n",
    "    print(\"'fare' column is not present in the DataFrame\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82af5417-8481-4dca-aee9-6a5ac3c60888",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_all = pd.DataFrame({\n",
    "    'Pclass': [1, 2, 3, 3, 1, 3],\n",
    "    'Parch': [0, 1, 0, 2, 0, 1],\n",
    "    'SibSp': [1, 0, 1, 1, 0, 0],\n",
    "    'Fare': [50, 30, 20, None, 70, None]\n",
    "})\n",
    "\n",
    "# Group by 'Pclass', 'Parch', 'SibSp' and calculate median of 'Fare'\n",
    "med_fare_series = df_all.groupby(['Pclass', 'Parch', 'SibSp'])['Fare'].median()\n",
    "\n",
    "# Print available index combinations\n",
    "print(\"Available groups and their median fares:\")\n",
    "print(med_fare_series)\n",
    "\n",
    "# Choose a valid group, or use a fallback\n",
    "try:\n",
    "    # Attempt to retrieve the median Fare for a specific group\n",
    "    med_fare = med_fare_series.loc[(3, 0, 0)]\n",
    "except KeyError:\n",
    "    # Use the overall median fare if the specific group is not present\n",
    "    print(\"Group (3, 0, 0) not found, using overall median fare instead.\")\n",
    "    med_fare = df_all['Fare'].median()\n",
    "\n",
    "# Fill missing values in 'Fare' with the computed median\n",
    "df_all['Fare'] = df_all['Fare'].fillna(med_fare)\n",
    "\n",
    "print(df_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56616e24-f4c8-44cd-98f6-5127a7738246",
   "metadata": {},
   "outputs": [],
   "source": [
    "#**Cabin**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c7d0842-16cd-4ddd-a1af-d2a89061cb7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_all.columns)\n",
    "# Check columns available after groupby operation\n",
    "grouped_df = df_all.groupby(['Pclass']).count()\n",
    "print(grouped_df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88b702d-35c4-4a31-a297-4d1548dc7c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust the list of columns to drop based on the existing columns\n",
    "columns_to_drop = ['Survived', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked', 'PassengerId', 'Ticket']\n",
    "existing_columns_to_drop = [col for col in columns_to_drop if col in grouped_df.columns]\n",
    "\n",
    "# Drop columns\n",
    "df_all_decks = grouped_df.drop(columns=existing_columns_to_drop).rename(columns={'Name': 'Count'}).transpose()\n",
    "print(df_all_decks)\n",
    "\n",
    "# Inspect initial columns of df_all\n",
    "print(df_all.columns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df0b52e2-e88e-4296-a8ce-f78a010aa4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by 'Pclass' and count\n",
    "grouped_df = df_all.groupby(['Pclass']).count()\n",
    "\n",
    "# Define columns to drop\n",
    "columns_to_drop = ['Survived', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked', 'PassengerId', 'Ticket']\n",
    "existing_columns_to_drop = [col for col in columns_to_drop if col in grouped_df.columns]\n",
    "\n",
    "# Drop existing columns and rename\n",
    "df_all_decks = grouped_df.drop(columns=existing_columns_to_drop, errors='ignore').rename(columns={'Name': 'Count'}).transpose()\n",
    "\n",
    "# Print or analyze the result\n",
    "print(df_all_decks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86380b77-47de-48f7-b313-e00f88cf41fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Deck column from the first letter of the Cabin column (M stands for Missing)\n",
    "df_all['Deck'] = df_all['Cabin'].apply(lambda s: s[0] if pd.notnull(s) else 'M')\n",
    "\n",
    "df_all_decks = df_all.groupby(['Deck', 'Pclass']).count().drop(columns=['Survived', 'Sex', 'Age', 'SibSp', 'Parch', \n",
    "                                                                        'Fare', 'Embarked', 'Cabin', 'PassengerId', 'Ticket']).rename(columns={'Name': 'Count'}).transpose()\n",
    "\n",
    "def get_pclass_dist(df):\n",
    "    \n",
    "    # Creating a dictionary for every passenger class count in every deck\n",
    "    deck_counts = {'A': {}, 'B': {}, 'C': {}, 'D': {}, 'E': {}, 'F': {}, 'G': {}, 'M': {}, 'T': {}}\n",
    "    decks = df.columns.levels[0]    \n",
    "    \n",
    "    for deck in decks:\n",
    "        for pclass in range(1, 4):\n",
    "            try:\n",
    "                count = df[deck][pclass][0]\n",
    "                deck_counts[deck][pclass] = count \n",
    "            except KeyError:\n",
    "                deck_counts[deck][pclass] = 0\n",
    "                \n",
    "    df_decks = pd.DataFrame(deck_counts)    \n",
    "    deck_percentages = {}\n",
    "\n",
    "    # Creating a dictionary for every passenger class percentage in every deck\n",
    "    for col in df_decks.columns:\n",
    "        deck_percentages[col] = [(count / df_decks[col].sum()) * 100 for count in df_decks[col]]\n",
    "        \n",
    "    return deck_counts, deck_percentages\n",
    "\n",
    "def display_pclass_dist(percentages):\n",
    "    \n",
    "    df_percentages = pd.DataFrame(percentages).transpose()\n",
    "    deck_names = ('A', 'B', 'C', 'D', 'E', 'F', 'G', 'M', 'T')\n",
    "    bar_count = np.arange(len(deck_names))  \n",
    "    bar_width = 0.85\n",
    "    \n",
    "    pclass1 = df_percentages[0]\n",
    "    pclass2 = df_percentages[1]\n",
    "    pclass3 = df_percentages[2]\n",
    "    \n",
    "    plt.figure(figsize=(20, 10))\n",
    "    plt.bar(bar_count, pclass1, color='#b5ffb9', edgecolor='white', width=bar_width, label='Passenger Class 1')\n",
    "    plt.bar(bar_count, pclass2, bottom=pclass1, color='#f9bc86', edgecolor='white', width=bar_width, label='Passenger Class 2')\n",
    "    plt.bar(bar_count, pclass3, bottom=pclass1 + pclass2, color='#a3acff', edgecolor='white', width=bar_width, label='Passenger Class 3')\n",
    "\n",
    "    plt.xlabel('Deck', size=15, labelpad=20)\n",
    "    plt.ylabel('Passenger Class Percentage', size=15, labelpad=20)\n",
    "    plt.xticks(bar_count, deck_names)    \n",
    "    plt.tick_params(axis='x', labelsize=15)\n",
    "    plt.tick_params(axis='y', labelsize=15)\n",
    "    \n",
    "    plt.legend(loc='upper left', bbox_to_anchor=(1, 1), prop={'size': 15})\n",
    "    plt.title('Passenger Class Distribution in Decks', size=18, y=1.05)   \n",
    "    \n",
    "    plt.show()    \n",
    "\n",
    "all_deck_count, all_deck_per = get_pclass_dist(df_all_decks)\n",
    "display_pclass_dist(all_deck_per)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ceff5d4-2eff-4b03-a3ad-5f7e63038c5f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
